\documentclass{article}

\usepackage[top=0.5in]{geometry}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{fullpage}
\usepackage{epstopdf}
\usepackage{float}
\usepackage{fancybox}
\usepackage{tikz}
\usepackage{subfloat}
\usepackage{subcaption}
\usepackage{color}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{latexsym}
\usepackage{amsthm}
\usepackage{eucal}
\usepackage{eufrak}
\usepackage{subfiles}
\usepackage{listings}
\usepackage{verbatim}
\usepackage{csquotes}
\usepackage{program}
\usepackage{mathtools}
\usepackage{boxedminipage}
\usepackage{enumitem}
\usepackage{tikz}

\usetikzlibrary{automata,positioning}

\newtheorem{definizione}{Definizione}[section]
\newtheorem{proposizione}{Proposizione}[section]
\newtheorem{corollario}{Corollario}[section]
\newtheorem*{dimostrazione*}{Dimostrazione}
\newtheorem{dimostrazione}{Dimostrazione}

\providecommand{\abs}[1]{\lvert#1\rvert}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

\newcommand*{\QED}{\hfill\ensuremath{\Box}}

\title{Appunti di Network Modeling}
\author{massimo.meneghello93}
\date{June 2018}

\begin{document}

\maketitle
\tableofcontents
\newpage


\section{Concetti di Probabilità}


\subsection{Distribuzioni Importanti}

\subsubsection{Distribuzione Esponenziale}

Una variabile aleatoria non negativa $T$ ha distribuzione esponenziale di parametro $\lambda >0$ se la funzione di densità di probabilità è
\begin{align*}
f_T = \left\{\begin{array}{l l}
\lambda e^{-\lambda t} & \text{ per } t \ge 0\\
0 & \text{ per } t < 0
\end{array}
\end{align*}
e con funzione di distribuzione
\begin{align*}
F_T(t) = P[T<t] = \left\{\begin{array}{l l}
1- e^{-\lambda t} & \text{ per } t \ge 0\\
0 & \text{ per } t < 0
\end{array}
\end{align*}
Valore atteso e varianza
\begin{gather*}
E[T] = \frac{1}{\lambda}\\
Var(T) = \frac{1}{\lambda^2}
\end{gather*}


\newpage
\section{Catene di Markov}


\subsection{Processi di Markov}

\begin{definizione}
Un processo di Markov $\{X_t\}$ è un processo aleatorio con la proprietà che, noto il valore di $X_t$, i valori di $X_s$ per $s > t$ non sono influenzati dai valori di $X_u$ per $u < t$.
\end{definizione}

In termini formali la \textit{proprietà di Markov} afferma che
$$
P[X_{n+1} = j \mid X_0 = i_0,\hdots,X_{n-1} = i_{n-1}, X_n = i] = P[X_{n+1} = j \mid X_{n} = i]
$$
Gli stati che un processo di Markov può assumere sono spesso indicati con gli interi positivi $0,\,1,\,\hdots$. La \textit{probabilità di transizione ad un passo} (cioè la probabilità che trovandosi in uno stato $i$ all'istante $n$-esimo, all'istante successivo ci si trovi nello stato $j$) è definita come
$$
P_{ij}^{n,n+1} = P[X_{n+1} = j \mid X_n = i] = P_{ij}
$$
Considerando tutti le possibili probabilità di transizione ad un passo si ottiene la \textit{matrice di Markov} relativa al processo
$$
P=
\left[\begin{array}{c c c c}
P_{00}&P_{01}&P_{02}&\hdots\\
P_{10}&P_{11}&P_{12}&\hdots\\
\vdots&\vdots&\vdots&\\
P_{i0}&P_{i1}&P_{i2}&\hdots\\
\vdots&\vdots&\vdots&
\end{array}\right]
$$
per la quale devono valere
\begin{align}
P_{i,j} \ge 0\qquad i,j = 0,1,2,\hdots\\
\sum_{j = 0}^{\infty} P_{ij} = 1 \qquad i = 0,1,2,\hdots
\end{align}
Un processo di Markov è completamente definito dalla sua matrice. Sia $P[X_0 = i] = p_i$, allora, grazie alla proprità di Markov possiamo eseguire la seguente computazione
\begin{align*}
P[X_0 = i_0, X_1 = i_1,\hdots,X_n = i_n] &= P[X_0 = i_0,X_1 = i_1, \hdots,X_{n-1} = i_{n-1}] \cdot \\
&\qquad P[X_n = i_n \mid X_0 = i_0, X_1 = i_1, \hdots, X_{n-1} = i_{n-1}]\\
&= P[X_0= i_0, X_1 = i_1,\hdots,X_{n-1} = I_{n-1}] \cdot P_{i_{n-1}i_n}\\
&= p_iP_{i_0i_1}P_{i_1i_2}\hdots P_{i_{n-1}i_n}
\end{align*}
Analizziamo ora la probabilità di transizione compiendo $n$ passi.
$$
P_{ij}^{(n)} = P[X_{n+m} = j \mid X_{m} = i] = P[X_n = j \mid X_0 = i]
$$
L'ultima uguaglienza deriva dalla \textit{proprietà di omogeneità} dei processi di Markov.
\begin{proposizione}
\label{mc_matrice_transizione_n_passi}
La matrice di transizione a $n$ passi soddisfa
$$
P_{ij}^{(n)} = \sum_{k = 0}^{\infty} P_{ik}\,P_{kj}^{(n-1)}
$$
dove
$$
P_{ij}^{(0)} =
\left\{\begin{array}{c l}
1 &\quad\text{se}\;i = j\\
0 &\quad\text{altrimenti}
\end{array}
$$
\end{proposizione}
\begin{dimostrazione*}
\begin{align*}
P_{ij}^{(n)} &= P[X_{n+m} = j \mid X_m = i] = P[X_n = j \mid X_0 = i]\\ 
&= \sum_{k = 0}^{\infty} P[X_n = j, X_1 = k \mid X_0 = i]\\
&=\sum_{k = 0}^{\infty} P[X_n = j \mid X_1 = k, X_0 = i]\cdot P[X_1 = k \mid X_0 =i]\\
&=\sum_{k =0 }^{\infty} P[X_n = j \mid X_1 = k] \cdot P[X_1 = k \mid X_0 = i]\\
&=\sum_{k = 0}^{\infty} P_{ik}\,P_{kj}^{(n-1)}
\end{align*}
\QED
\end{dimostrazione*}

\subsection{Analisi di Primo Passo}

Consideriamo la seguente matrice di Markov
\begin{align*}
P = \left[\begin{array}{c c c}
1 & 0 & 0\\
\alpha & \beta & \gamma\\
0 & 0 & 1
\end{array}
\right]
\end{align*}
con $\alpha,\,\beta\,,\gamma > 0$ e $\alpha + \beta + \gamma = 1$.
Vogliamo trovare i valori di
\begin{gather*}
u = P[X_T = 0 \mid X_0 = 1]\\
v = E[T \mid X_0 = 1]
\end{gather*}
dove $T = \min\{n \ge 0\,:\,X_n = 0,\,X_n = 2\}$, quindi vogliamo conoscere qual è la probabilità che il processo resti intrappolato nello stato $0$ sapendo che lo stato iniziale è $1$ e vogliamo anche conoscere quanto tempo dovremmo attendere affinché questo accada (valore atteso).\\

Conoscendo la scomposizione vista in \ref{mc_matrice_transizione_n_passi} osserviamo che
\begin{align*}
u &= P[X_T = 0 \mid X_0 = 1] = P_{10}^{(T)}\\
&= \sum_{k = 0}^2 P_{1k}\,P_{k0}^{(T-1)}\\
&= P_{10}\,P_{00}^{(T-1)} + P_{11}\,P_{10}^{(T-1)} + P_{12}\,P_{20}^{(T-1)}\\
&= \alpha\,(1) + \beta\,(u) + \gamma\,(0)\\
&= \alpha + \beta u = \frac{\alpha}{1-\beta} = \frac{\alpha}{\alpha + \gamma}
\end{align*}
Abbiamo anche utilizzata l'uguaglianza $P_{ij}^{(T)} = P_{ij}^{(T-1)}$. Mentre per il valore atteso degli istanti impiegati abbiamo
\begin{align*}
v &= 1 + \alpha\,(0) + \beta\,(v) + \gamma\,(0)\\
&= 1 + \beta v\\
&= \frac{1}{1 - \beta} = \frac{1}{\alpha + \gamma}
\end{align*}\\

In generale possiamo avere matrici di Markov come la seguente, di dimensione $(N+1) \times (N+1)$:
\begin{align}
\label{mc_matrice_QR}
P = \left[\begin{array}{c c}
\textbf{Q} & \textbf{R}\\
\textbf{O} & \textbf{I}
\end{array}\right]
\end{align}
dove \textbf{O} è una matrice $(N-r+1)\times r$ di zeri e \textbf{I} è una matrice identità $(N-r+1)\times(N-r+1)$.
In questa matrice possiamo riconoscere due tipi di stati (le cui definizioni formali verrano fornite successivamente):
\begin{itemize}
    \item \textit{transient}, cioè gli stati da $0,\hdots,r-1$ per i quali vale $P_{ij}^{(n)} \to 0$ quando $n \to \infty$ per $0\le i,j < r$;
    \item \textit{absorbing}, gli stati da $r,\hdots,N$ per i quali $P_{ii} = 1$ per $r \le i \le N$.
\end{itemize}
Otteniamo
\begin{align*}
u_i = U_{ik} &= P[\text{Assorbimento in k} \mid X_0 = i] \quad \text{per} \quad 0 \le i < r\\
&= P_{ik} + \sum_{j = 0}^{r-1} P_{ij}U_{jk}
\end{align*}
mentre il tempo medio di assorbimento vale
\begin{align*}
v_i = 1 + \sum_{j = 0}^{r-1}P_{ij}\,v_j \quad \text{per} \quad 0 \le i < r
\end{align*}
Dall'$n$-esima potenza della matrice di Markov è possibile calcolare
\begin{itemize}
    \item il numero medio di visite su uno stato $j$
    \item il tempo medio fino all'assorbimento della catena
    \item la probabilità di assorbimento in uno stato $k$.
\end{itemize}
Tutte questo dipende dallo stato iniziale $X_0 = i$. L'$n$-esima potenza della matrice \ref{mc_matrice_QR} è facilmente ottenibile
\begin{align}
P^{n} = \left[\begin{array}{c c}
\textbf{Q}^{n} & (\textbf{I}+\textbf{Q}+\textbf{Q}^2+\hdots+\textbf{Q}^{n-1})R\\
\textbf{O} & \textbf{I}
\end{array}\right]
\end{align}
Forniamo un'interpretazione per $P^n$:
\begin{align*}
W_{ij}^{(n)} &= \text{numero medio di visite allo stato $j$ in $n$ passi partendo dallo stato $i$}\\
&= E\left[\sum_{l=0}^n\textbf{1}\{X_l = j\} \mid X_0 = i\right] \text{ma poiché } E[\textbf{1}\{X_l = j\} \mid X_0 = i] = P_{ij}^{(l)}\\
&= \sum_{l=0}^n E[\mathbf{1}\{X_l = j\} \mid X_0 = i]\\
&= \sum_{l=0}^n P_{ij}^{(n)}
\end{align*}
Abbiamo quindi trovato che
\begin{align*}
W^{(n)} &= \textbf{I} + \textbf{Q} + \textbf{Q}^2 + \hdots + \textbf{Q}^{n}\\
&= \textbf{I} + \textbf{Q}\,(\textbf{I} + \hdots + \textbf{Q}^{n-1})\\
&= \textbf{I} + \textbf{Q}\,W^{(n-1)}
\end{align*}
Passando al limite otteniamo
\begin{align*}
W_{ij} = \lim_{n\to \infty} W_{ij}^{(n)} = E[\text{visite totali a $j$ }\mid X_0= i] \quad 0 \le i,j < r
\end{align*}
mentre in forma matriciale si ottiene
\begin{align*}
W = \textbf{I} + \textbf{Q}\,W
\end{align*}
e quindi
\begin{align}
\label{mc_matrice_fondamentale_Q}
W = (\textbf{I} - \textbf{Q})^{-1}
\end{align}
che è detta \textit{matrice fondamentale associata a Q}.

\subsection{Catene di Markov speciali}

\subsubsection{Catena di Markov a due stati}

Sia data la matrice
\begin{align*}
P = \left[\begin{array}{c c}
1 - a & a\\
b & 1-b
\end{array}\right] \quad \text{con} \quad 0 < a,b < 1
\end{align*}
allora l'$n$-esima potenza di $P$ vale 
\begin{align*}
P^{(n)} = \frac{1}{a+b}\left[\begin{array}{c c}
b & a\\
b & a
\end{array}\right] + \frac{(1 -a - b)^n}{a+b}
\left[\begin{array}{c c}
a &-a\\
-b & b
\end{array}\right] \quad \text{per} \quad n \ge 0
\end{align*}
che può essere facilmente dimostrato per induzione.

\subsubsection{Passeggiata casuale unidimensionale}

\subsubsection{Success Runs}

\subsection{Tempi di primo passaggio}

Si è interessati nel conoscere quanto tempo è necessario (in media) per raggiungere uno stato $j$ partendo da uno stato $i$.
\begin{gather*}
\theta_{ij} = \text{numero di transizioni per raggiungere $j$ da $i$ per la prima volta}\\
P[\theta_{ij} = n] = f_{ij}(n) = P[X_n = j,\,X_m \neq j,\,m = 1,\,\hdots,\,n-1 \mid X_0 = i] 
\end{gather*}
Abbiamo la relazione ricorsiva
\begin{align*}
f_{ij}(n) = \left\{\begin{array}{l c}
P_{ij} & n = 1\\
\sum_{k\neq j} P_{ik}f_{kj}(n-1) & n > 1
\end{array}
\end{align*}\\

\begin{boxedminipage}{\textwidth}
\textbf{IMPORTANTE.} Per calcolare la il valore atteso del tempo di primo passaggio tra 2 stati $i$ e $j$ usiamo
\begin{align*}
E[\theta_{ij}] &= P_{ij} + \sum_{k \neq j}\,P_{ik}\,(1+E[\theta_{kj}])\\
&= 1 + \sum_{k \neq j} \, P_{ik}\, E[\theta_{kj}] \quad \forall\,i,j
\end{align*}
Questo comporta la risoluzione di un sistema di equazioni. In particolar modo, se si vuole calcolare $E[\theta_{ii}]$ tutte le variabili nella parte destra non sono note. Tuttavia, come vi vedrà più avanti alla proposizione \ref{mc_teorema_limite_fondamentale} abbiamo che
\begin{align*}
E[\theta_{ii}] = m_i = \lim_{n\to\infty}\frac{1}{P_{ii}^{(n)}} = \frac{1}{\pi_i}
\end{align*}
Per calcolare il secondo momento (necessario per trovare la varianza) del tempo di primo passaggio usiamo
\begin{gather*}
E[\theta_{ij}^2] = 2\,E[\theta_{ij}] - 1 + \sum_{k \neq j}P_{ik}\,E[\theta_{kj}^2]\\
Var(\theta_{ij}) = E[(\theta_{ij} - E[\theta_{ij}])^2] = E[\theta_{ij}^2] - E[\theta_{ij}]^2
\end{gather*}
\end{boxedminipage}

\subsection{Comportamento asintotico delle catene di Markov}

\begin{definizione}
Una catena di Markov si dice \textit{regolare} se la $k$-esima potenza della matrice $P$ associata alla catena ha tutti elementi strettamente positivi, quindi se
$$
P_{ij}^{(k)} > 0\quad \forall\,i,j
$$
\end{definizione}
La caratteristica più importante di questa catena è l'esistenza di una distribuzione di probabilità al limite
$$
\pi = (\pi_0,\hdots,\pi_N) \text{ con } \pi_j > 0 \quad \forall\,j \text{ e } \sum_j \pi_j = 1
$$
che è indipendente dallo stato iniziale della catena.\\

\begin{boxedminipage}{\textwidth}
\textbf{IMPORTANTE.} Questi concetti sono utili per conoscere come evolve una catena di Markov all'infinito, quindi per sapere dove in che stato potremmo trovarla.
\begin{proposizione}
Sia $P$ una matrice di probabilità di transizione regolare con stati $0,1,\hdots,N$. Allora la distribuzione limite $\vec{\pi} = (\pi_0,\hdots,\pi_N)$ è l'unica soluzione non negativa del sistema
$$
\left\{\begin{array}{l}
\pi_j = \sum_{k=0}^N \pi_k P_{kj}\qquad j = 0,\hdots,N\\
\sum_{k=0}^N \pi_k = 1
\end{array}
$$
con $\pi_k = \lim_{n \to \infty} P_{ik}^{(n-1)}$.
\end{proposizione}
Risolvendo questo sistema di $N+1$ incognite e $N+2$ equazioni (un'equazione è ridondante e può essere rimossa)otteniamo il vettore $\vec{\pi}$ che ci permette di conoscere
\begin{align*}
\lim_{n\to\infty} P^n = \left[\begin{array}{c c c c}
\pi_0 & \pi_1 & \hdots & \pi_N\\
\pi_0 & \pi_1 & \hdots & \pi_N\\
\vdots & \vdots & & \vdots\\
\pi_0 & \pi_1 & \hdots & \pi_N
\end{array}\right]
\end{align*} 
\end{boxedminipage}

\subsection{La classificazione degli stati}
Lo stato $j$ è detto \textit{raggiungibile} dallo stato $i$ ($i \to j$) se $P_{ij}^{(n)} > 0$ per qualche $n \ge 0$. Due stati sono detti \textit{comunicanti} ($i \leftrightarrow j$) se $i$ è raggiungibile da $j$ e viceversa.

\begin{proposizione}
Il concetto di \textit{comunicazione} è una relazione di equivalenza.
\end{proposizione}
\begin{dimostrazione*}
Si dimostrano le proprietà di una relazione di equivalenza.
\begin{enumerate}
    \item \textbf{proprietà riflessiva}, $i \leftrightarrow i$ vale perché $P_{ii}^{(0)} = 1$
    \item \textbf{proprietà simmetrica}, $i \leftrightarrow j \Rightarrow j \leftrightarrow i$
    \item \textbf{proprietà transitiva}, $i \leftrightarrow k$ e $k \leftrightarrow j \Rightarrow i \leftrightarrow j$, infatti se $i \leftrightarrow k$ e $k \leftrightarrow j$ allora esitono $n,m$ tali che $P_{ik}^{(n)} > 0$ e $P_{kj}^{(m)} > 0$, quindi $P_{ij}^{(n+m)} = \sum_{r=0}^{\infty} P_{ir}^{(n)}P_{rj}^{(m)} \ge P_{ik}^{(n)}P_{kj}^{(m)} > 0$
\end{enumerate}
\QED
\end{dimostrazione*}
Una catena di Markov è detta \textit{irriducibile} se tutti gli stati comunicano tra di loro (quindi se tutti gli stati appartendono a un'unica classe di equivalenza).

\subsubsection{Periodicità di una catena di Markov}

\begin{proposizione}
\label{mc_periodo_prop_classe}
Se $i \leftrightarrow j$ allora $d(i) = d(j)$ (il periodo è una proprietà di classe).
\end{proposizione}
\begin{dimostrazione*}
Sia $S_i = \{s > 0 : P_{ii}^{(s)} > 0\}$. Allora esistono $m,n$ tali che
\begin{gather*}
P_{ij}^{(m)} > 0,\quad P_{ji}^{(n)} > 0\\
\forall\,s \in S_i,\, P_{ii}^{(s)} > 0\\
P_{jj}^{(n+s+m)} = \sum_{h,k}\,P_{jh}^{(n)}\,P_{hk}^{(s)}\,P_{kj}^{(m)} \ge P_{ji}^{(n)}\,P_{ii}^{(s)}\,P_{ij}^{(m)} > 0
\end{gather*}
Se $s \in S_i$ allora $n + s + m \in S_j$. Analogamente $P_{ii}^{(2s)} \ge (P_{ii}^{(s)})^2 > 0$. Quindi $n+2s+m \in S_j$ e di conseguenza $n+s+m$ è multiplo intero di $n+2s+m$.
$$
n+2s+m -n-s-m = s \in S_j
$$
Se $s \in S_i$ allora è multiplo di $d(j)$. Quindi $d(j)$ è divisore comune di $S_i$, $d(i)$ è MCD di $S_i$. Ma allora $d(i)$ è multiplo di $d(j)$. Per simmetria $d(j)$ multiplo di $d(i)$ quindi $d(i) = d(j)$.
\QED
\end{dimostrazione*}

\subsubsection{Stati ricorrenti e stati transitori}

\begin{proposizione}
\begin{gather*}
i \text{ ricorrente } \Leftrightarrow \sum_{n=1}^{\infty} P_{ii}^{(n)} = \infty\\
i \text{ transitorio } \Leftrightarrow \sum_{n=1}^{\infty} P_{ii}^{(n)} < \infty
\end{gather*}
\end{proposizione}

\begin{proposizione}
\label{mc_i_comm_j_ricor}
Se $i \leftrightarrow j$ e $i$ ricorrente, allora anche $j$ è ricorrente.
\end{proposizione}
\begin{dimostrazione*}
Dall'ipotesi $i \leftrightarrow j$ sappiamo che esistono $m, n \ge 1$ tali che
$$
P_{ij}^{(n)} > 0,\quad P_{ji}^{(m)} > 0
$$
Sia $l > 0$. Sapendo che
$$
P_{jj}^{(m+n+l)} = \sum_{h,k} P_{jh}^{(m)}\,P_{hk}^{(l)}\,P_{kj}^{(n)} \ge P_{ji}^{(m)}\,P_{ii}^{(l)}\,P_{ij}^{(n)} 
$$
Sommando otteniamo
$$
\sum_{n=1}^{\infty} P_{jj}^{(n)} \ge \sum_{l =1}^{\infty} P_{jj}^{(m+n+l)} \ge P_{ji}^{(m)}\,P_{ij}^{(n)}\,\sum_{l=1}^{\infty} P_{ii}^{(l)} = \infty
$$
(La sommatoria diverge perché $i$ è ricorrente)
\QED
\end{dimostrazione*}

\subsection{Teorema Fondamentale delle Catene di Markov}

Ricordiamo che
\begin{align*}
f_{ii}^{(n)} &= P[X_n = i, X_m \neq i, m = 1,\hdots,n-1 \mid X_0 = i]\\
&= P[R_i = n \mid X_0 = i] \quad \text{ con } \quad R_i = \min\{n \ge 1\;;\; X_n = i\}
\end{align*}
La durata media tra due visite è quindi definita come
\begin{gather}
m_i = E[R_i \mid X_0 = i] = \sum_{n = 1}^{\infty} n \, f_{ii}^{(n)}
\end{gather}
\begin{definizione}
Se $m_i < \infty$ allora $i$ si dice \emph{ricorrente positivo} ($\pi_i > 0$) mentre se $m_i = \infty$ allora $i$ si rice \emph{ricorrente nullo} ($\pi_i = 0$). 
\end{definizione}

\begin{proposizione}
\label{mc_teorema_limite_fondamentale}
Consideriamo una catena di Markov aperiodica, irriducibile, ricorrente. Sia $P_{ii}^{(n)}$ la probabilità di essere nello stato $i$ alla transizione $n$-esima per $n=0,1,2,\hdots$ e sia dato lo stato iniziale $X_0 = i$ (per convenzione si assume $P_{ii}^{(0)} = 1$). Sia $f_{ii}^{(n)}$ la probabilità di primo ritorno allo stato $i$ nella stansizione $n$-esima, dove $f_{ii}^{(0)} = 0$. Allora
\begin{align}
\lim_{n\to \infty} P_{ii}^{(n)} = \frac{1}{\sum_{n=0}^{\infty} n\,f_{ii}^{(n)}} = \frac{1}{m_i}
\end{align}
Sotto le medesime condizioni abbiamo anche che
\begin{align}
\lim_{n\to\infty} P_{ji}^{(n)} = \lim_{n\to\infty} P_{ii}^{(n)}\quad \forall\,j
\end{align}
\end{proposizione}

\begin{proposizione}
\label{mc_numero_finito_di stati}
In una catena di Markov con un numero finito di stati deve esserci almeno uno stato ricorrente positivo.
\end{proposizione}
\begin{dimostrazione*}
(Per assurdo) Supponiamo che tutti gli stati siano transitori o ricorrenti nulli, quindi
$$
1 = \sum_{j=0}^N P_{ij}^{(n)}\quad \forall\,n,\,i
$$
Per $n \to \infty$:
$$
1 = \lim_{n \to \infty} \sum_{j=0}^N P_{ij}^{(n)}=\sum_{j=0}^N \lim_{n\to \infty} P_{ij}^{n} = 0
$$
Assurdo.
\QED
\end{dimostrazione*}


\newpage
\section{Processi di Poisson}


\subsection{Distribuzione di Poisson}

La distribuzione di Poisson con parametro $\mu > 0$ è data da
\begin{align}
\label{pp_distribuzione_poisson}
p_k = e^{-\mu}\,\frac{\mu^k}{k!}\quad \text{ per } k = 0,1,\hdots
\end{align}
Media e varianza di una variabile aleatoria di Poisson sono date da
\begin{gather*}
E[X] = \mu\\
E[X^2] = \mu^2 + \mu\\
Var(X) = E[(X - E[X])^2] = E[X^2] - E[X]^2 = \mu  
\end{gather*}

\begin{proposizione}
\label{pp_somma_due_poisson}
Siano $X$ e $Y$ due variabili aleatorie (indipendenti) con distribuzione di Poisson, rispettivamente di parametro $\mu$ e $\lambda$. Allora $Z = X + Y$ è una variabile aleatoria di Poisson con con parametro $\mu + \lambda$.
\end{proposizione}
\begin{dimostrazione*}
\begin{align*}
P[X + Y = n] &= \sum_{k=0}^n\,P[X=k,Y=n-k]\\
&= \sum_{k=0}^n\,P[X = k]\,P[Y = n-k]\\
&= \sum_{k = 0}^n\,e^{-\mu}\frac{\mu^k}{k!}\,e^{-\lambda}\frac{\lambda^{n-k}}{(n-k)!}\\
&= e^{-(\mu+\lambda)}\frac{1}{n!}\sum_{k=0}^n\,\frac{n!}{k!(n-k)!}\mu^k\lambda^{n-k}\\
&= e^{-(\mu+\lambda)}\,\frac{(\mu+\lambda)^n}{n!}
\end{align*}
\QED
\end{dimostrazione*}

\subsection{Processi di Poisson}

\begin{definizione}
Un processo di Poisson di intensità $\lambda > 0$ è un processo stocastico a valori interi $\{X(t)\,;\,t \ge 0\}$ per il quale
\begin{enumerate}
    \item per ogni valore di tempo $t_0 = 0 < t_1 < \hdots < t_n$, il gli incrementi del processo
    $$
    X(t_1) - X(t_0), \hdots, X(t_n) - X(t_{n-1})
    $$
    sono variabili aleatorie indipendenti;
    \item per $s \ge 0$ e $t > 0$ la variabile aleatoria $X(s+t) - X(s)$ ha distribuzione di Poisson
    $$
    P[X(s+t) - X(s) = k] = e^{-\lambda\,t}\,\frac{(\lambda\,t)^k}{k!} \quad \text{ per } k=0,1,\hdots
    $$
    \item $X(0) = 0$
\end{enumerate}
\end{definizione}

\begin{proposizione}
\label{pp_tempi_interarrivo}
In un processo di Poisson di parametro $\lambda$ i tempi di interarrivo sono variabili aleatorie indipendenti con distribuzione esponenziale e valore atteso $\frac{1}{\lambda}$.
\end{proposizione}
\begin{dimostrazione*}
Sia
\begin{align*}
&P[s_0 > t] = P[\text{ nessun arrivo in }(0,t]] = e^{-\lambda t}\\
&P[s_1 > t\mid s_0 = s] = \frac{P[s_1 > t, s_0 = s]}{P[s_0 = s]} = P[s_1 > t] = e^{-\lambda t}
\end{align*}
Quindi possiamo generalizzare il procedimento per qualunque $s_i$. 
\QED
\end{dimostrazione*}

\begin{proposizione}
\label{pp_dens_congiunta_variabili}
Siano $W_1,W_2,\hdtos$ i tempi di occorrenza in un processo di Poisson con $\lambda > 0$. Dato $N(t) =n$, la densità congiunta delle variabili $W_1,W_2,\hdtos,W_n$ è
\begin{align*}
f_{W_1,W_2,...,W_n}(w_1,w_2,\hdots,w_n) = \frac{n!}{t^n}\quad\text{ con }\quad 0<w_1<w_2<\hdots<w_n\le t
\end{align*}
\end{proposizione}

\begin{boxedminipage}{\textwidth}
\begin{proposizione}
\label{pp_prob_condizionata_binomiale}
Sia $X(t)$ un processo di Poisson con $\lambda > 0$. Allora
\begin{gather}
P[X(u) = k \mid X(t) = n] = \frac{n!}{k!\,(n-k)!} \left(\frac{u}{t}\right)^k\left(1-\frac{u}{t}\right)^{n-k}
\end{gather}
con $0<u<t$ e $0\le k \le n$.
\end{proposizione}
\begin{dimostrazione*}
Conseguenza diretta della proposizione \ref{pp_dens_congiunta_variabili}. Essendo nota l'informazione $X(t) = n$, il modo in cui gli $n$ eventi possono distribuirsi nell'intervallo $[0,t]$ è equivalente ad un esperimento ripetuto $n$ volte, con probabilità di successo $\frac{u}{t}$ (cioè che l'evento accada nell'intervallo di lunghezza $u$ incluso in $t$). Vogliamo conoscere con che probabilità questo esperimento si ha esito positivo $k$ volte. Questo giustifica l'uso della densità binomiale. 
\end{dimostrazione*}

Una proprietà significativa
\begin{align}
P[X_1(t) = k \mid X_1(t) + X_2(t) = n] = \frac{n!}{k!(n-k)!}\left(\frac{\lambda_1}{\lambda_1+\lambda_2}\right)^k\left(\frac{\lambda_2}{\lambda_1+\lambda_2}\right)^{n-k}
\end{align}
\end{boxedminipage}
\bigbreak
\begin{boxedminipage}{\textwidth}
\textbf{IMPORTANTE.} Supponiamo di fornire un servizio al quale arrivano richeste secondo una distribuzione di Poisson con parametro $\lambda$. Ogni richiesta ha durata $Y_1,Y_2,\hdots$, variabili aleatorie con funzione di distribuzione comune $G(y) = P[Y_k \le y]$. Gli arrivi sono invece regolati dalle variabili $W_1,W_2,\hdots$ \textit{che possiamo far diventare variabili aleatorie uniformi}.\\
Sia $M(t)$ una variabile che conta le richieste attive in un dato istante $t$ con $M(0) = 0$ e sia $X(t)$ il numero totale di richieste arrivate fino all'istante $t$. Allora
\begin{align*}
M(t) &= \sum_{k=1}^{X(t)} \textbf{1}\{W_k + Y_k \ge t\}
\end{align*}
Sia
\begin{align*}
p &= P[U_k + Y_k \ge t] = \frac{1}{t}\int_0^t P[Y_k \ge t - u]\,du\\
&= \frac{1}{t}\int_0^t [1-G(t-u)]\,du = \frac{1}{t} \int_0^t [1-G(z)]\,dz
\end{align*}
Conoscendo il numero $n$ di richieste totali fino all'istante $t$, la probabilità condizionata fornisce
\begin{align*}
P[M(t) = m \mid X(t) = n] = \frac{n!}{m!(n-m)!} p^m (1-p)^{n-m}
\end{align*}
mentre
\begin{align*}
P[M(t) = m] = e^{-\lambda\,p\,t}\frac{(\lambda\,p\,t)^m}{m!}
\end{align*}
Il numero di richieste esistenti al tempo $t$ è un processo di Poisson con media
\begin{align*}
E[M(t)] &= \lambda\,p\,t\\
&= \lambda \int_0^t [1-G(z)]\,dz
\end{align*}
\end{boxedminipage}


\newpage
\section{Processi di Rinnovamento}


\subsection{Definizione di Processi di Rinnovamento e Concetti Correlati}
\begin{definizione}
Uno processo contatore (di rinnovamento) è un processo stocastico non negativo a valori interi denominato con $N(t), t \ge 0$. Il processo registra le occorrenze successive di un evento nell'intervallo temporale $(0,t]$, dove i tempi tra eventi consecutivi sono variabili aleatorie i.i.d positive.
\begin{itemize}
    \item $F(x) = P[X_k \le x]$, distribuzione delle variabili aleatorie $X_k$.
    \item $W_n = X_1+X_2+\hdots+X_n$, tempo di attesa per l'evento $n$-esimo.
\end{itemize}
\end{definizione}
Nella teoria dei processi di rinnovamento è fondamentale derivare proprietà di alcuni variabili aleatorie associate a $N(t)$ e $W_n$ conoscendo la distribuzione $F$. Ad esempio
\begin{align*}
E[N(t)] = M(t)
\end{align*}
che è detta \emph{funzione di rinnovamento}.
\begin{align*}
P[W_n \le x] = F_n(x) = \int_0^{\infty} F_{n-1}(x-y)\,dF(y)\\
P[N(t) = k] = F_k(t) - F_{k+1}(t)\\
M(t) = E[N(t)] = \sum_{k=1}^{\infty}P[W_k \le t]=\sum_{k=1}^{\infty}F_k(t)
\end{align*}
Tre variabili risultano di particolare interesse:
\begin{itemize}
    \item $\gamma_t = W_{N(t) + 1}-t$, \emph{vita residua};
    \item $\delta_t = t - W_{N(t)}$, \emph{vita corrent};
    \item $\beta_t = \gamma_t + \delta_t$, \emph{vita totale}.
\end{itemize}

\subsection{Processi di Poisson Come Processi di Rinnovamento}

\begin{gather*}
P[N(t) = k] = e^{-\lambda t}\,\frac{(\lambda t)^k}{k!}\\
M(t) = E[N(t)] = \lambda t
\end{gather*}
Vita totale media:
\begin{align*}
E[\beta_t] &= E[\gamma_t] + E[\delta_t]\\
&= \frac{1}{\lambda} + \int_0^{\infty}P[\delta_t > y]\,dy\\
&= \frac{1}{\lambda} + \frac{1}{\lambda}(1-e^{-\lambda t}) \to \frac{2}{\lambda} \text{ per } t \gg \frac{1}{\lambda}
\end{align*}

\subsection{Comportamento Asintotico dei Processi di Rinnovamento}

\begin{proposizione}
Con probabilità pari a $1$ vale
\begin{align}
\lim_{t\to\infty} \frac{N(t)}{t} = \frac{1}{\mu}
\end{align}
\end{proposizione}
\begin{dimostrazione*}
\begin{gather*}
S_{N(t)} \le t < S_{N(t) +1}\\
\frac{S_{N(t)}}{N(t)} \le \frac{t}{N(t)} < \frac{S_{N(t) +1}}{N(t)}\\
\frac{S_{N(t)}}{N(t)} \le \frac{t}{N(t)} < \frac{S_{N(t) +1}}{N(t)+1}\cdot\frac{N(t)+1}{N(t)}\\
E[X] \le \lim_{t\to\infty}\frac{t}{N(t)} < E[X]\cdot1 \text{ con } E[X] = \mu
\end{gather*}
\QED
\end{dimostrazione*}

\subsection{Equazioni di Rinnovamento}

\begin{definizione}
Sia $a(t)$ una funzione nota, $F(t)$ funzione di distribuzione della variabile aleatoria $X$. Allora
\begin{align*}
A(t) = a(t)+\int_0^tA(t-x)\,dF(x)
\end{align*}
è detta \emph{equazione di rinnovamento}.
\end{definizione}

\begin{proposizione}
\label{pr_proposizione_soluzione_equazione_rinnovamento}
Sia $a(t)$ una funzione limitata. Allora
\begin{align*}
A(t) = a(t)+\int_0^tA(t-x)\,dF(x)
\end{align*}
ha un'unica soluzione $A$ limitata su un intervallo finito e questa è
\begin{align*}
A(t) = a(t)+\int_0^ta(t-x)\,dM(x)
\end{align*}
con $M(t) = \sum_{k=1}^{\infty} F_k(t)$ è la funzione di rinnovamento.
\end{proposizione}

Grazie al risultato della proposizione \ref{pr_proposizione_soluzione_equazione_rinnovamento} possiamo dimostrare questa importante relazione
\begin{align*}
E[S_{N(t) + 1}] &= E[X_1 + X_2 + \hdots + X_{N(t) + 1}]\\
&= E[\sum_{i = 1}^{N(t) + 1} X_i]\\
&\vdots\\
&= \mu\,E[M(t) + 1]\quad \text{ con } \mu = E[X_1]
\end{align*}
dove le $X_1,X_2,\hdots$ sono variabili aleatorie \emph{indipendenti e identicamente distribuite} mentre $N$ è un valore casuale.
Usando l'argomento di rinnovamento possiamo infatti scrivere
\begin{align*}
A(t) &= E[S_{N(t) + 1}]\\
&=\int_0^{\infty}E[S_{N(t)+1}] \mid X_1 = x]\,dF(x)\\
&=\int_0^t [x + A(t-x)]\,dF(x) + \int_t^{\infty}x\,dF(x)\\
&=\int_t^{\infty}x\,dF(x)+\int_0^tA(t-x)\,dF(x)\\
&=E[X_1]+\int_0^tA(t-x)\,dF(x)\\
&=E[X_1]+\int_0^tE[X_1]\,dM(t) \quad \text{ per il teorema \ref{pr_proposizione_soluzione_equazione_rinnovamento}}\\
&=E[X_1][M(t) + 1]
\end{align*}

\subsection{Stopping Time}

\begin{proposizione}[Equazione di Wald]
Siano $X_1,X_2,\hdots$ variabili aleatorie i.i.d. con valore atteso finito ($E[X_i] < \infty$) e sia $N$ uno \emph{stopping time} per $X_1,X_2,\hdots$ allora
\begin{align*}
E[\sum_{n=1}^{N} X_n] = E[N]\,E[X]
\end{align*}
\end{proposizione}

\subsection{Teorema Elementare di Rinnovamento}

\begin{proposizione}[Teorema Elementare di Rinnovamento]
\label{pr_teorema_elementare_rinnovamento}
Sia $X_i$ un processo di rinnovamento con $\mu = E[X_i] < \infty$. Allora
\begin{align}
\lim_{t\to\infty} \frac{M(t)}{t} = \frac{1}{\mu}
\end{align}
\end{proposizione}
\begin{dimostrazione*}
Sappiamo che $t<S_{N(t)+1}$, usando $E[S_{N(t)+1}] = E[X_1]\cdot[M(t)+1]$ otteniamo
\begin{gather*}
\frac{M(t)}{t} > \frac{1}{\mu} - \frac{1}{t} \Rightarrow \lim_{t\to\infty} \frac{M(t)}{t} \ge \frac{1}{\mu}
\end{gather*}
Sia
\begin{align*}
X_i^c = \left\{\begin{array}{l l}
X_i & \text{ se } X_i \le c\\
0 & \text{ se } X_i > c
\end{array}
\end{align*}
\emph{(Stuff)}.
\begin{gather*}
X_i^c \le X_i \Rightarrow N^c(t)\ge N(t) \Rightarrow M^c(t) \ge M(t)
\end{gather*}
\emph{(Avendo $X_i^c$ vita più breve di $X_i$, nello stesso periodo temporale $(0,t]$ si registrano più avvenimenti)}.
\begin{gather*}
t+c \ge \mu_c\,(1+M(t)) \Rightarrow \frac{M(t)}{t} \le \frac{1}{\mu_c} + \frac{1}{t}\left(\frac{c}{\mu_c}-1\right)
\end{gather*}
e questo porta al limite superiore
\begin{gather*}
\lim_{t\to\infty}\frac{M(t)}{t} \le \frac{1}{\mu_c} \quad \forall\,c
\end{gather*}
Non resta che verificare che $\mu_c$ tende a $\mu$. Abbiamo che \emph{(con grafico di $X_i^c$ si capisce meglio)}
\begin{align*}
\lim_{c\to\infty} \mu_c &= E[X_i^c]\\
&= \lim_{c\to\infty}\int_0^{c} P[X_i^c > c]\,dx\\
&= \int_{0}^{\infty}[1-F(x)]\,dx\\
&= \mu
\end{align*}
\QED
\end{dimostrazione*}


\newpage
\section{Altri Concetti Utili all'Analisi}

\subsection{Processi Semi-Markoviani}

Un processo semi-markoviano cambia stato in accordo ad una catena di Markov ma la transizione da uno stato $i$ ad uno stato $j$ richiede una quantità casuale di tempo.
\begin{enumerate}
    \item Se $i$ è lo stato corrente, lo stato successivo sarà $j$ con probabilità $P_{ij}$.
    \item Sapendo che lo stato corrente è $i$ e il prossimo stato sarà $j$, il tempo necessario alla transizione ha distribuzione $F_{ij}(t)$.
\end{enumerate}
Sia quindi $Z(t)$ lo stato all'istante $t$, $\{Z(t),t\ge 0\}$ è un processo semi-markoviano mentre $\{X_n, n\ge 0\}$ è detta \emph{catena inclusa nel processo} (embedded chain).

Distribuzione del tempo associato alla visita dello stato $i$-esimo.
\begin{align}
H_i(t) = \sum_j = P_{ij}F_{ij}(t)
\end{align}

Tempo medio che trascorro nello stato $i$-esimo prima della transizione.
\begin{align}
\mu_i =\int_0^{\infty} x\,dH_i(x)
\end{align}

Sia $T_{ii}$ il tempo tra due passaggi nello stato $i$-esimo, allora $\mu_{ii} = E[T_{ii}]$.

\begin{proposizione}
Se il processo $Z$ è irriducibile e $E[T_{ii}] < \infty$ allora
\begin{align}
P_i = \lim_{t\to\infty} P[Z(t) = i\mid Z(0) = j] = \frac{\mu_i}{\mu_{ii}}
\end{align}
\end{proposizione}

\begin{proposizione}
Con probabilità $1$ vale
\begin{align}
\lim_{t\to\infty} \frac{\text{tempo speso in $i$ durante $[0,t]$}}{t} = \frac{\mu_i}{\mu_{ii}}
\end{align}
\end{proposizione}

\begin{proposizione}
Se la catena inclusa nel processo è ricorrente positiva, allora
\begin{align}
P_j = \frac{\pi_j \mu_j}{\sum_i \pi_i \mu_i}
\end{align}
dove $\pi$ è la distribuzione asintotica della catena inclusa.
\end{proposizione}

\begin{boxedminipage}{\textwidth}
\textbf{IMPORTANTE.} Sia $P$ la matrice della catena di markov inclusa e $T$ la matrice dei tempi medi associati alle transizioni ($T_{ij}$ è il tempo medio che il processo impiega per andare dallo stato $i$ allo stato $j$). Allora i tempi medi di permanenza sono dati da
\begin{align*}
\mu_i = \sum_i P_{ij}T_{ij}
\end{align*}
\end{boxedminipage}


\newpage
\section{Analisi di Code e Protocolli}


\subsection{Coda M/G/1}
\begin{itemize}
    \item $M$, la distribuzione degli arrivi è esponenziale, quindi gli arrivi sono un processo di Poisson;
    \item $G$, i server hanno distribuzione generica $G$;
    \item $1$, ho un solo server.
\end{itemize}
Non si tratta di un processo di Markov, è necessario adottare delle ipotesi semplificatrici. Sia $X_n$ la variabile che conta il numero di elementi in coda nell'$n$-esimo slot di tempo e sia $Y_n$ la variabile che indica il numero di arrivi durante il tempo di servizio tra $t_n$ e $t_{n+1}$, allora
\begin{align*}
X_{n+1} = \left\{\begin{array}{l l}
X_n - 1 + Y_n & \text{ se } X_n > 0\\
Y_n & \text{ se } X_n = 0
\end{array}
\end{align*}
Essendo gli arrivi un processo di Poisson sono tra loro indipendenti, la probabilità che in uno slot temporale di durata $x$ arrivino $j$ nuovi pacchetti è
\begin{align*}
a_j &= P[Y_n = j]\\
&= E[P[Y_n = j \mid \text{tempo di servizio } = x]]\\
&= E[e^{-\lambda x}\frac{(\lambda x)^j}{j!}]\\
&= \int_0^{\infty}e^{-\lambda x} \frac{(\lambda x)^j}{j!}\,dG(x)
\end{align*}
Da questa probabilità si possono derivare le probabilità di transizione di $X$
\begin{align*}
P_{ij} = P[Y_n = j -i + 1] = \left\{\begin{array}{l l}
\int_0^{\infty} e^{-\lambda x} \frac{(\lambda x)^j}{j!}\, dG(x) & i \ge 1,\;j \ge i-1\\
0 & j < i -1
\end{array}
\end{align*}

La matrice del processo sarà quindi
\begin{align*}
P = \left[\begin{array}{c c c c}
a_0 & a_1 & a_2 & \hdots \\
a_0 & a_1 & a_2 & \hdots \\
0 & a_0 & a_1 & \hdots \\
0 & 0 & a_0 & \hdots \\
\vdots & \vdots & \vdots & \ddots
\end{array}\right]
\end{align*}


\subsection{Coda G/M/1}

\subsection{Esempi di Protocolli di Livello 2 e 4}

\subsubsection{Protocollo 1}
All'inizio di ogni slot temporale trasmetto il contenuto del buffer fino ad un massimo di $M$ pacchetti.
\begin{align*}
X_{n+1} = \left\{\begin{array}{l l}
Y_n & \text{ se } X_n \le M\\
X_n - M + Y_n & \text{ se } X_n > M
\end{array}
\end{align*}

\subsubsection{Protocollo 2}
All'inizio di ogni slot temporale trasmetto il contenuto del buffer solo se sono presenti almeno $m$ pacchetti. Ho due casi:
\begin{itemize}
    \item trasmetto tutto il contenuto del buffer
\begin{align*}
X_{n+1} = \left\{\begin{array}{l l}
Y_n & \text{ se } X_n \ge m\\
X_n + Y_n & \text{ se } X_n < m
\end{array}
\end{align*}

    \item trasmetto fino ad un massimo di $M \ge m$ pacchetti
\begin{align*}
X_{n+1} = \left\{\begin{array}{l l}
X_n + Y_n & \text{ se } X_n < m\\
Y_n & \text{ se } m \le X_n \le M\\
X_n - M + Y_n & \text{ se } X_n > M
\end{array}
\end{align*}
\end{itemize}

\subsection{ALOHA}

\subsection{Go-Back-N}

Si tratta di un protocollo di livello $2$ che si impegna a ritrasmettere i pacchetti corrotti. Il canale di trasmissione può assumere due stati:
\begin{itemize}
    \item \emph{good}, indicato con $0$ o con \textbf{G};
    \item \emph{bad}, indicato con $1$ o con \textbf{B}.
\end{itemize}
Quando una trasmisione non è buona (\textbf{B}) si ritrasmette lo stesso pacchetto dopo $m-1$ slot temporali. $m$ è il tempo di \emph{round-trip}.\\
Siamo interessati a calcolare il throughput
\begin{align*}
\text{throughput} = \frac{\text{\# slot buoni}}{\text{\# totale di slot}} = \lim_{t\to\infty}\frac{N(t)}{t}
\end{align*}
Si tratta di un canale con memoria. Metrica del tempo:
\begin{itemize}
    \item $1$ per stato \textbf{G} (durata $1$ se esco dallo stato buono);
    \item $m$ per stato \textbf{B} (durata $m$ se esco dallo stato non buono).
\end{itemize}
Metrica di successo:
\begin{itemize}
    \item $R_G = 1$ per stato \textbf{G};
    \item $R_B = 0$ per stato \textbf{B}.
\end{itemize}
Matrice della catena di Markov inclusa:
\begin{align*}
P = \left[\begin{array}{c c}
p_{00} & p_{01}\\
p_{10}(m) & p_{11}(m)
\end{array}\right]
\end{align*}
Quindi le distribuzioni asintotiche dei due stati risultano essere
\begin{gather*}
\pi_G = \frac{p_{10}(m)}{p_{01} + p_{10}(m)} \quad \pi_B = \frac{p_{01}}{p_{01} + p_{10}(m)}
\end{gather*}
mentre il throughput vale
\begin{align*}
\text{throughput} &= \frac{\pi_G R_G + \pi_B R_B}{\pi_G T_G + \pi_B T_B}\\
&= \frac{p_{10}(m)}{p_{10}(m) + m\,p_{01}}
\end{align*}
Supponiamo ora che esista un canale di ritorno per fornire un feedback, con probabilità di errore $\delta$. Con i nuovi stati \textbf{$G_0$}, \textbf{$G_1$}, \textbf{B} la matrice di transizione diventa
\begin{align*}
P = \left[\begin{array}{c c c}
(1-\delta)\,p_{00} & \delta\,p_{00} & p_{01}\\
(1-\delta)\,p_{00}(m) & \delta\,p_{00}(m) & p_{01}(m)\\
(1-\delta)\,p_{10}(m) & \delta\,p_{10}(m) & p_{11}(m)\\
\end{array}\right]
\end{align*}
Ora le probabilità stazionarie valgono
\begin{gather*}
\pi_{G_1} = \pi_{G_0}\frac{\delta}{1-\delta} \quad \pi_B = 1-\frac{\pi_{G_0}}{1-\delta} \quad \pi_{G_0} = \frac{(1-\delta)\,p_{10}(m)}{(1-\delta)\,p_{01} + \delta\,p_{01}(m) + p_{10}(m)} 
\end{gather*}
mentre il throughput
\begin{gather*}
\text{throughput} = \frac{\pi_{G_0}}{\pi_{G_0} + m\,(1-\pi_{G_0})}
\end{gather*}


\newpage
\section{Per Esame}


\subsection{Soluzioni Esercizi}

\subsubsection{Compito 22 settembre 2005}
\begin{enumerate}
    \item\begin{enumerate}[label=\alph*)]
        \item $\vec{\pi} = (\frac{40}{72},\frac{15}{72},\frac{17}{72})$
        \item $m_{31}=1$, $v_{31}=0$
        \item $m_{13}=\frac{55}{17}$, $v_{13}=\frac{1490}{289}$
        \item $P[X_1 = 1, X_3 = 1\mid X_2 = 2] = \frac{1}{5}$, $P[X_2 = 2\mid X_1 = 1, X_3 = 1] = \frac{2}{17}$
    \end{enumerate}

    \item Risoluzione come processo semi-markoviano. Le matrici incluse e dei tempi sono rispettivamente:
    \begin{align*}
    P=\left[\begin{array}{c c c}
    0 & 1 & 0\\
    \alpha & 0 & 1-\alpha\\
    1 & 0 & 0
    \end{array}\right]
    \quad
    T=\left[\begin{array}{c c c}
    - & 1/\lambda & -\\
    2 &- &\beta\\
    0 & -& -
    \end{array}\right]
    \end{align*}
    dove $\alpha =P[X(2)=0]$ è la probabilità che non arrivi alcun pacchetto entro $2$ secondi, mentre $\beta$ è il tempo medio che il secondo pacchetto impiega per arrivare, essendo noto che questo arrivi, quindi
    \begin{align*}
    \beta &= E[\text{ tempo arrivo pacchetto }\mid\text{ il pacchetto arriva }]\\
    &= \frac{1}{1-e^{-2\lambda}}\int_0^2x\lambda e^{x\lambda}\,dx\\
    &= \frac{1-3e^{-2\lambda}}{1-e^{-2\lambda}}
    \end{align*}
    \begin{enumerate}[label=\alph*)]
        \item La frazione di tempo in cui la coda è vuota vale $\frac{\mu_0}{\mu_0+\mu_1+\mu_2}=\frac{1}{2-e^{-2}}$.
        \item $E[\text{ ritardo }] P[\text{ coda piena }] = 1 - \frac{1}{2-e^{-2}} = \frac{1-e^{-2}}{2-e^{-2}}$.
    \end{enumerate}

    \item\begin{enumerate}[label=\alph*)]
        \item $E[X(\frac{1}{10})] = 10(1-e^{-1})$, $E[X(\frac{1}{6})] = 10(1-e^{-5/3})$, $\lim_{t\to\infty}E[X(t)] = 10$, 
        \item $P[X(\frac{1}{10})=10]=e^{-r}\frac{r^{10}}{10!} = 0.05$, con $r=10(1-e^{-1})$, $\lim_{t\to\infty}P[X(t) = 10] = e^{\lambda / \mu}\frac{(\lambda / \mu)^{10}}{10!}= 0.125$.
        \item
        \begin{align*}
        \lambda p t = \left\{\begin{array}{l l}
        \lambda t & t < 2\\
        \lambda \int_2^t \left(1-\frac{z-2}{8}\right)\,dz & 2\le t\le10\\
        6\lambda & t > 10
        \end{array}
        \end{align*}
        Quindi $E[X(6)] = 2\lambda + \lambda \int_2^6 \left(1-\frac{z-2}{8}\right)\,dz = 5\lambda$, mentre $E[X(10)] = 2\lambda + \lambda \int_2^{10} \left(1-\frac{z-2}{8}\right)\,dz = 6\lambda$.
        Per l'ultimo punto abbiamo invece $P[X(t) = 10]$ per $t=6,\infty$, quindi $\lambda p t = 25/3$, $P[X(6)=10] = 0.107$ e $\lambda p t = 10$ per $\lim_{t\to\infty}P[X(t)=10]=0.125$. 
    \end{enumerate}

    \item Canale markoviano con $p_{00} = 0.99$ e $p_{10} = 0.1$:
    \begin{enumerate}[label=\alph*)]
        \item $\text{thp} = \frac{p_{10}(2)}{p_{10}(2)+m\,p_{01}} = \frac{189}{209} = 0.904$
        \item $\text{thp} = \frac{\pi_{G_0}}{\pi_{G_0}+m\,(1-\pi_{G_0})} = 0.74$
    \end{enumerate}

\end{enumerate}

\subsubsection{Compito 14 luglio 2006}
\begin{enumerate}
    \item\begin{enumerate}[label=\alph*)]
        \item La distribuzione di probabilità di $X_1$ corrisponde alla prima riga della matrice $P$, la distribuzione di $X_2$ corrisponde alla prima riga di $P^2$ mentre la distribuzione di $X_{500}$ corrisponde al vettore $\vec{\pi} = (\frac{10}{27},\frac{12}{27},\frac{5}{27})$.
        \item $m_{00} = \frac{1}{\pi_0} = \frac{27}{10}$, $m_{01} = \frac{5}{2}$, $m_{02} = \frac{9}{2}$.
        \item $W^3 = I + P + P^2 + P^3$ la prima riga vale $(1.964,1.284,0.752)$, $W=(I-P)^{-1}$.
    \end{enumerate}
    
    \item\begin{enumerate}[label=\alph*)]
        \item
        \item
        \item
    \end{enumerate}
    
    \item\begin{enumerate}[label=\alph*)]
        \item
        \item
        \item
    \end{enumerate}
    
    \item Canale markoviano con $p_{00} = 0.98$ e $p_{10} = 0.1$:
    \begin{enumerate}[label=\alph*)]
        \item $\text{thp} = \frac{p_{10}(2)}{p_{10}(2)+m\,p_{01}} = \frac{705}{874} = 0.806$
        \item $\text{thp} = \frac{\pi_{G_0}}{\pi_{G_0}+m\,(1-\pi_{G_0})} = \frac{403}{597} = 0.675$
    \end{enumerate}
\end{enumerate}

\subsubsection{Compito 12 dicembre 2006}
\begin{enumerate}
    \item\begin{enumerate}[label=\alph*)]
        \item Le classi in cui la catena si scompone sono $C_1 = \{0,4\}$ periodica di periodo $1$, $C_2 = \{2\}$ transitoria e $C_3=\{1,3,5\}$ ricorrente.
        \item Per la classe $C_1$ abbiamo $\vec{\pi} = (1/2,1/2)$ mentre per $C_3$ (essendo la sottomatrice di questa classe doppiamente stocastica) $\vec{\pi} = (1/3,1/3,1/3)$. Partendo dallo stato $2$ la probabilità di andare in $C_1$ è $2/5$ mentre di andare in $C_3$ è $3/5$. Abbiamo quindi:
        \begin{align*}
        \lim_{n\to\infty} P^n = \left[\begin{array}{c c c c c c}
        - & 0& 0& 0& - & 0\\
        0 & 1/3& 0& 1/3& 0 & 1/3\\
        - & 1/5& 0& 1/5& - & 1/5\\
        0 & 1/3& 0& 1/3& 0 & 1/3\\
        - & 0& 0& 0& - & 0\\
        0 & 1/3& 0& 1/3& 0 & 1/3\\
        \end{array}\right]
        \end{align*}
        \item Con la media temporale possiamo inserire i valori che non hanno un limite definito:
        \begin{align*}
        \lim_{n\to\infty}\frac{1}{n}\sum_{i=1}^n P^i = \left[\begin{array}{c c c c c c}
        1/2 & 0& 0& 0& 1/2 & 0\\
        0 & 1/3& 0& 1/3& 0 & 1/3\\
        1/5 & 1/5& 0& 1/5& 1/5 & 1/5\\
        0 & 1/3& 0& 1/3& 0 & 1/3\\
        1/2 & 0& 0& 0& 1/2 & 0\\
        0 & 1/3& 0& 1/3& 0 & 1/3\\
        \end{array}\right]
        \end{align*}
        \item $P[X_4 = 5,X_2 = 3\mid X_3 = 1,X_1=3] = P_{15}\cdot P_{31}\cdot P_{33}/P_{31}^{(2)} = 0.122$.
    \end{enumerate}
    
    \item\begin{enumerate}[label=\alph*)]
        \item
        \item
    \end{enumerate}
    
    \item\begin{enumerate}[label=\alph*)]
        \item $P[X_1(3) = 1\mid X_1(3)+X_2(3)=3] = \binom{3}{1} 0.5^4 = 0.1875$, $P[X_1(3)+X_2(3)= 3\mid X_1(3)=1]=P[X_2(3)=2]=0.112$.
        \item $P[X_1(2)=1\mid X_1(3)=3] = 2/9 = 0.222$, $P[X_1(3)=3\mid X_1(2)=1]=P[X_1(1)=2]=0.251$.
    \end{enumerate}
    
    \item\begin{enumerate}[label=\alph*)]
        \item
        \item
        \item
    \end{enumerate}
\end{enumerate}

\subsubsection{Compito 09 luglio 2007}
\begin{enumerate}
    \item\begin{enumerate}[label=\alph*)]
        \item Conoscendo lo stato iniziale $X_0 = 0$, la distribuzione di probabilità per $X_1$ corrisponde alla prima riga della matrice di transizione $P$, la distribuzione di $X_2$ corrisponde alla prima riga della matrice $P^2$ mentre la distribuzione per $X_{500}$ abbiamo $P^{500} \approx P^{\infty}$, quindi è necessario calcolarsi $\vec{\pi} = (0.5,0.25,0.25)$ con le tecniche note. 

        \item Calcolare i tempi medi di primo passaggio è lungo ma non difficile (si veda l'apposita sezione), abbiamo $m_{02} = 3$, $m_{12} = 2$, $m_{22} = 4$.  

        \item Ottenere il risultato può essere un po' lungo ma bassa applicare la proprietà di Markov e la formula di Bayes, $P[X_1 = 1, X_3 = 1\mid X_2 = 1] = \frac{1}{15}$, $P[X_2 = 1 \mid X_1 = 1, X_3 = 1] = \frac{1}{3}$.
    \end{enumerate}
    
    \item\begin{enumerate}[label=\alph*)]
        \item $\frac{\beta^2}{(\alpha + \beta)^2} = 0.01$, $\frac{1}{2\beta} = 1.5$ giorni.
        \item $24\cdot\frac{\alpha^2}{(\alpha + \beta)^2}+12\cdot\frac{2\alpha\beta}{(\alpha + \beta)^2} = 21.6$
        \item $30\cdot\frac{\alpha^2}{(\alpha + \beta)^2}+12\cdot\frac{2\alpha\beta}{(\alpha + \beta)^2} = 26.46$
    \end{enumerate}
    
    \item Processo semi-markoviano.
    \begin{enumerate}[label=\alph*)]
        \item \begin{align*}
        P = \left[\begin{array}{c c c}
        0 & 1 & 0\\1-\alpha & 0 & \alpha\\1 & 0 & 0
        \end{array}\right]
        \end{align*}

        \item\begin{align*}
        T = \left[\begin{array}{c c c}
        -&T&-\\\beta T&-&\frac{\beta T}{2}\\\gamma T&-&-\\
        \end{array}\right]
        \end{align*}
    \end{enumerate}

    \item Processi di Poisson, facile andandosi a vedere le formule.
    \begin{enumerate}[label=\alph*)]
        \item $P[X(0.1) = 0] = e^{-2} = 0.1353$
        \item $P[X(0.1) = 0\mid X(0.5) = 10] = 0.8^{10}$
    \end{enumerate}
\end{enumerate}

\subsubsection{Compito 09 luglio 2007}
\begin{enumerate}
    \item\begin{enumerate}[label=\alph*)]
        \item
        \item
        \item
    \end{enumerate}
    
    \item\begin{enumerate}[label=\alph*)]
        \item Il traffico smaltito vale $2000 / E[\text{ tempo ciclo }] = 2000/(E[\text{ coda vuota }] + E[\text{ 1 coda piena }] + E[\text{ tempo trasmissione }]) = 2000 / (\frac{1}{2\lambda} + \frac{1}{\lambda} + 10^{-3}) = 0.5 \text{ Mbps}$ che è un quarto della capacità massima del nodo.
        \item
        \item
    \end{enumerate}
    
    \item\begin{enumerate}[label=\alph*)]
        \item
        \item
        \item
    \end{enumerate}
    
    \item\begin{enumerate}[label=\alph*)]
        \item
        \item
    \end{enumerate}
\end{enumerate}

\subsection{Dimostrazioni}
\begin{itemize}
    \item \textbf{Dimostrare che il periodo è una proprietà di classe:} vedi proposizione \ref{mc_periodo_prop_classe}.

    \item \textbf{Dimostrare che se $i \leftrightarrow j$ e $i$ ricorrente, allora anche $j$ è ricorrente:} vedi proposizione \ref{mc_i_comm_j_ricor}.

    \item \textbf{Si consideri una passeggiata casuale sugli interi non negativi con le seguenti probabilità di transizione: $P_{01} = 1$, $P_{i,i+1} = p$, $P_{i,i-1} = q$ con $i > 0$ e $p+q = 1$. Se ne studi il comportamento, caratterizzandone in particolare la ricorrenza o transitorietà e ricavandone la distribuzione stazionaria:}

    \item \textbf{Dare la definizione di stato riconente e dimostrare che uno stato $i$ è riconente se e solo se $\sum_{n=1}^{\infty}P_{ii}^{(n)}=\infty$:}

    \item \textbf{Dimostrare che in una catena di Markov con un numero finito di stati non possono esserci stati ricorrenti nulli:}
    \begin{dimostrazione*}
    Suppongo che esista uno stato ricorrente nullo. Allora deve esistere una classe ricorrente nulla con un numero finito di stati ma questo è impossibile per il teorema \ref{mc_numero_finito_di stati}.
    \end{dimostrazione*}

    \item \textbf{Dimostrare che se $X$ e $Y$ sono due variabili aleatorie con distribuzione di Poisson, rispettivamente di parametri $\mu$ e $\lambda$ allora $X+Y$ è una variabile di Poisson con parametro $\mu + \lambda$:} vedi proposizione \ref{pp_somma_due_poisson}.

    \item \textbf{Si dimostri che per un processo di Poisson $X(t)$ la statistica $X(s)$ condizionata a $X(t)$, con $s<t$, è binomiale e si fornisca l'espressione di $P[X(s) = k\mid X(t) = n]$:} vedi proposizione \ref{pp_prob_condizionata_binomiale}.

    \item \textbf{Dimostrare che $E[S_{N(t) + 1}] = E[X_k]\,[M(t) + 1]$ con $E[X_1] = \mu$:} la dimostrazione è resa possibile dalla proposizione \ref{pr_proposizione_soluzione_equazione_rinnovamento} e segue la dimostrazione del teorema.

    \item \textbf{Enunciare e dimostrare il teorema elementare di rinnovamento:} vedi proposizione \ref{pr_teorema_elementare_rinnovamento}.

    \item \textbf{Dimostrare che per un processo di rinnovamento $M(t) < \infty$ per ogni $t$ intero. (Sugg.: si ricordi che $M(t) = \sum_{k=1}^{\infty}F_k(t)$):}
\end{itemize}

\end{document}